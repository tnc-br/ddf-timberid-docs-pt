# üìó Glossary



<table><thead><tr><th width="183">Term</th><th></th></tr></thead><tbody><tr><td>Stable Isotopes</td><td>Stable isotopes are elements with the same number of protons but different number of neutrons. Stable Isotopes are useful for timber origin verification because they vary by geography and are absorbed by trees.<br>For example, carbon has two stable isotopes: 12C and 13C. 12C has six electrons, six protons, and six neutrons, and 13C has six electrons, six protons, and seven neutrons.</td></tr><tr><td>Isoscape</td><td>An isoscape is a map (geotif) of a geographic area where each location (pixel) represents the ratio of an isotope to its more common form..<br>So a Œ¥18O isoscape would be similar to a topographic map, but instead of showing elevation, would show at each point the ratio between stable isotopes oxygen-18 (18O) and oxygen-16 (16O).</td></tr><tr><td>Training Set</td><td>The entity for which the input is obtained is a known trusted source (such as Dr. Martinelli). This means that the ‚ÄòInput Location‚Äô is known a priori to be ‚ÄòTruthful‚Äô and the Isotope metrics are intended to be included in the ‚ÄòTrusted Isoscape‚Äô.</td></tr><tr><td>Validation Set </td><td>The entity represents a known trusted source. Samples included in a validation set are used for parameter tuning and to measure and detect overfit when performance on the training set is better than the validation (and test) set..</td></tr><tr><td>Test Set </td><td>The entity represents a known trusted source, but whose data is not included in training. The samples used for validation in this document will come from a consistent Test set.</td></tr><tr><td>Field/DOF Set</td><td>An input that is done in our online system against an actual untrusted Supplier or test subject for which we cannot trust the given location.</td></tr><tr><td>Simulated</td><td>Simulated Isotope values were generated from some other data source, like taking point samples from an already generated isoscape from Craig Gordon.</td></tr><tr><td>Field-Sampled</td><td>Isotope values were taken by a mass spectrometer from a sample taken directly in the field.</td></tr><tr><td>Fraudulent (Positive)</td><td>Fraudulent Locations are a location that isn‚Äôt the accurate location of the tree whose Isotope values were measured/simulated. Note that the ‚ÄòInput Isotope Metric‚Äô could still match (through happenstance) what it should be at the input location. Location is our Label.</td></tr><tr><td>non-Fraud (Negative)</td><td>Accurate locations that represent the actual original location of the tree whose sample was taken and Isotopes measured (or simulated).</td></tr><tr><td>Predicted Location</td><td>A location predicted by one of the models.</td></tr><tr><td>Known Location</td><td>A location provided by a trusted source.</td></tr><tr><td>True</td><td>The model correctly predicted that the location was either Fraud or not Fraud. A True Positive happens when the Model correctly predicts a Fraudulent Location. A True Negative happens when the Model correctly confirms the stated Location is accurate.</td></tr><tr><td>False</td><td>The model did not correctly predict that the location was either Fraud or not Fraud A False Positive happens when the Model incorrectly predicts a Fraudulent Location. A False Negative happens when the Model incorrectly confirms the stated Location is accurate.</td></tr><tr><td>RMSE</td><td><p>A measure of the average error between predicted (mean isotope) values and observed ground truth values of the isotope ratios.</p><p>RMSE = sqrt(mean( (predicted - observed)^2 ))</p></td></tr><tr><td>Precision</td><td><p>Ratio of true positives to total classified positives. True positives are invalid DOFs labeled ‚Äúinvalid‚Äù. See: https://en.wikipedia.org/wiki/Precision_and_recall which includes a good picture.</p><p>Precision = (number of correctly measured Fraud)/(total measured Fraud)</p><p>(True Predicted Positive / Total Predicted Positives)</p></td></tr><tr><td>Recall</td><td><p>Ratio of true positives to total positives. Ie How much fraud we detect. See https://en.wikipedia.org/wiki/Precision_and_recall</p><p>Recall = (number of correctly identified invalid DOFs)/(total Fraud in the set)</p><p>True Predicted Positives / Total Known Positives</p></td></tr><tr><td>P-value threshold</td><td><p>The p-value is a measure of how likely it is that two groups of observations represent the same distribution. A low p-value in our t-test indicates that two distributions (the ground truth and sample being tested) are dissimilar, which should cause a positive (fraud) result.</p><p>As we decrease the p-value threshold, we will see fewer indications of fraud, with the intention of increasing precision at the expense of recall.</p></td></tr><tr><td>Last Known Good Isoscape</td><td>The isoscape geotiff per element that is currently considered highest quality and intended for use in higher level analytics and production use cases.</td></tr><tr><td>Simulated Fraud Percent</td><td>The percentage of the total Test Set that should be simulated as Fraud.</td></tr><tr><td>Simulated Radius</td><td>The simulated radius controls the extent of fraudulent locations from the ground truth sample location generated by the validation test.<br>We currently simulate fraud from the entire Amazon, but have designed the system to adjust to how real fraud occurs.</td></tr><tr><td>Allowed Radius</td><td>The allowed radius is a buffer area for which the null hypothesis is confirmed (the sample‚Äôs stated location is truthful).<br>This radius allows for a permitted area to match a given timber sample.</td></tr></tbody></table>

